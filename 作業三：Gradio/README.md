# 作業三：Gradio

## Creating a multimodal pipeline with Gradio

In this homework, you will create a multimodal pipeline with the following components:

1. Speech to text to convert audio to text
2. Large language model to generate text based on the input text
3. Text to speech to convert the generated text to audio

Adapted from: https://www.gradio.app/guides/real-time-speech-recognition

### Load Speech to Text Model (20%)

It should take in speech from Gradio and output text.

Check out this guide to see how to complete it:

https://www.gradio.app/guides/real-time-speech-recognition

### Load LLM (20%)

Check the docs to see how to load the model.
Define `call_llm` which takes a string as input and returns a string as output.

Docs: https://huggingface.co/microsoft/Phi-3-mini-128k-instruct

### Load Text to Speech model  (20%)

Docs: https://huggingface.co/microsoft/speecht5_tts

### Putting it all together  (20%)

Complete the pipeline by feeding the output of the speech to text model to the LLM and then the output of the LLM to the text to speech model.

### Create the Gradio Interface (20%)

1. The input should accept audio either from a microphone or uploaded
2. The output is THREE elements:
    - The text generated by STT: the label should be "STT Output
    - The text generated by the LLM: the label should be "LLM Output"
    - The audio generated by the TTS: the label should be "TTS Output"

**Make sure that it runs!**

Check out the Gradio documentation for help:

https://www.gradio.app/guides/quickstart

Here is sample audio that is known to work:
[My dog is cooler](https://drive.google.com/file/d/1JWvL-VRT_PIRtKIleQViHfxJnwpZmtEW/view?usp=sharing)

Your interface should look like this:

![gradio](https://i.imgur.com/na0GKvW.png)