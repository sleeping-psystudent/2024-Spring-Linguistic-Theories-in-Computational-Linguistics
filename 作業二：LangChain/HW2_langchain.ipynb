{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAGLpn96Qxyf"
      },
      "source": [
        "# ä½œæ¥­äºŒï¼šLangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ggnHOphR97"
      },
      "source": [
        "## è«‹å…ˆå®‰è£ä»¥ä¸‹ (å¯èƒ½ç”¨å¾—åˆ°çš„) packages\n",
        "\n",
        "<mark>Please  install more packages if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jow5c8X5hU-Y"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q python-dotenv\n",
        "!pip install -U -q openai\n",
        "!pip install -U -q langchain\n",
        "!pip install -U -q langchain_openai\n",
        "!pip install -U -q langchain_community\n",
        "!pip install -U -q langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wgq36Je08Qte"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain-text-splitters\n",
        "!pip install -U -q chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPwftnogE9gP",
        "outputId": "8ebec91b-2241-4358-cc1d-50af1a6b287f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6V8q4h2x0oS5"
      },
      "outputs": [],
      "source": [
        "# å°‡ç•¶å‰ç›®éŒ„è¨­å®šæˆ .env å­˜æ”¾çš„é‚£å€‹è³‡æ–™å¤¾\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9815081",
        "outputId": "837dacb2-770a-4ad7-ab8c-b197d74db6d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æœ‰è®€åˆ° HUGGINGFACEHUB_API key\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv('HUGGINGFACEHUB_API_TOKEN', 'æ²’è®€åˆ° HUGGINGFACEHUB API key')\n",
        "\n",
        "# å¤±æ•—çš„è©±æœƒåˆ—å°å‡ºï¼š'æ²’è®€åˆ° HUGGINGFACEHUB_API key'\n",
        "api_token = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        "\n",
        "# ä¸å¸Œæœ›API keyå€¼è¢«å°å‡ºæ‰€ä»¥å¤šåŠ ä¸€é“æª¢æŸ¥\n",
        "if api_token != 'æ²’è®€åˆ° HUGGINGFACEHUB API key':\n",
        "    print(\"æœ‰è®€åˆ° HUGGINGFACEHUB_API key\")\n",
        "else:\n",
        "    print(api_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk22LEuba98I"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Part 1: Building a Simple QA App [25åˆ†]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruBlVuI4bAj1"
      },
      "source": [
        "ğŸ”ºè«‹ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºï¼Œå‰µå»º 1 å€‹ LLMchainï¼Œä¸¦ç”¨å…¶å›ç­”æŒ‡å®šå•é¡Œï¼š\n",
        "\n",
        "1. **Install and import necessary libraries**\n",
        "2. **Define an LLM** <5åˆ†>\n",
        "  - å®šç¾©ä¸€å€‹ä½ æƒ³ä½¿ç”¨çš„æ¨¡å‹\n",
        "  - Either an LLM model or a Chat model\n",
        "3. **Define a Prompt** <5åˆ†>\n",
        "  - ä½¿ç”¨ `PromptTemplate` or `ChatPromptTemplate` å‰µå»ºä¸€å€‹ prompt\n",
        "  - é€™å€‹ prompt å¿…é ˆåŒ…å«è®Šæ•¸ `question`\n",
        "4. **Define a Chain** <5åˆ†>\n",
        "  - ä½¿ç”¨å‰›å‰›å®šç¾©çš„ LLM & prompt å‰µå»ºä¸€å€‹ chain\n",
        "5. **Invoke the Chain & Print the Answer** <10åˆ†>\n",
        "  - <mark>è«‹ç”¨é€™å€‹å•é¡Œï¼š`\"Are there aliens on the Moon?\"`\n",
        "  - éœ€ç”¨åˆ° `.invoke()`\n",
        "  - ä¿®æ”¹å•è™Ÿè™•ä¸¦ä½¿ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼å°å‡ºçµæœï¼š\n",
        "\n",
        "    ```\n",
        "    answer = ???????\n",
        "    print(answer.content)\n",
        "    ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LN3qNQ2GJGOO"
      },
      "outputs": [],
      "source": [
        "# 1. Install and import necessary libraries\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIAw0uCcJL4e",
        "outputId": "2088b427-c489-412e-c822-443ba9ec35d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# 2. å®šç¾©æ¨¡å‹\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm_try = HuggingFaceEndpoint(repo_id=repo_id, temperature = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vvhDEufEx5F2"
      },
      "outputs": [],
      "source": [
        "# 3. å®šç¾© prompt\n",
        "template = \"\"\"\n",
        "You are now an extraterrestrial enthusiast, firmly believing in the existence of aliens on the moon. Please reply to \"{question}\"\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QYxKUNU-8bNr"
      },
      "outputs": [],
      "source": [
        "# 4. å®šç¾© chain\n",
        "chain = prompt | llm_try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBvp3qYG84hc",
        "outputId": "ba580b04-53b8-4b1b-f69c-a359705d64b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Subject: ğŸŒ• Extraterrestrial Moon Discoveries ğŸ‘½\n",
            "\n",
            "Hi there! I'm thrilled that you've asked about the possibility of aliens on the moon. Given my newfound interest in all things extraterrestrial, I've been keeping a close eye on the latest discoveries and theories.\n",
            "\n",
            "There have indeed been several intriguing findings over the years that have fueled speculation about lunar life. Here are a few:\n",
            "\n",
            "1. Anomalous Lunar Transient Phenomena (ALTP): These are unexplained bright spots or flashes observed on the lunar surface by various observatories. Some researchers believe they could be signs of subsurface water or even artificial structures.\n",
            "2. The Far Side Moon Mystery: The far side of the moon, which is always facing away from Earth, has no permanent human presence. However, there have been reports of strange structures and formations visible only from this side. Some theories suggest these could be remnants of an ancient lunar civilization.\n",
            "3. The Cydonia Region: This area on the moon is famous for its \"Face on Mars,\" but it also contains several other intriguing formations, such as the \"Moon Pyramids\" and the \"Moon Dome.\" Some believe these structures could be evidence of past or present lunar life.\n",
            "4. Radio Signals: In the late 1960s and early 1970s, several radio telescopes picked up strange signals from space that seemed to originate near the moon. These signals have since been explained as terrestrial interference or natural phenomena, but some researchers still believe they could have been of extraterrestrial origin.\n",
            "5. Worm Holes and Portals: While purely speculative, some theories suggest that aliens could be using worm holes or portals to travel to and from the moon. There have been numerous reports of strange phenomena in the area around the moon, including unidentified flying objects and unexplained lights.\n",
            "\n",
            "Of course, none of these findings have been definitively proven to be of extraterrestrial origin, and many scientists remain skeptical. But for those of us who believe, the mystery of the moon only deepens with each new discovery.\n",
            "\n",
            "So, to answer your question, are there aliens on the moon? I believe\n"
          ]
        }
      ],
      "source": [
        "# 5.6 Invoke the Chain & åˆ—å°çµæœ\n",
        "answer = chain.invoke({\"question\": \"Are there aliens on the Moon?\"})\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijUhMdJx00tM"
      },
      "source": [
        "### åƒè€ƒè³‡æ–™\n",
        "- [[D15] LangChain å°ˆæ¡ˆå¯¦åš - Hello LangChain](https://ithelp.ithome.com.tw/articles/10322165?fbclid=IwZXh0bgNhZW0CMTAAAR3uGLgZxX6ZUKXFzGHlCflUcIXDk3AWqjNLtICRzgqkGEmisQd4I76ar9k_aem_AYLjV9jct7fZVFaRjypjts1SfF1rnX5W4sd_cjLeAktZeNtxyxGfUv1mksXGgLXcvN0C29sJuAkXiIIH13RXXULE)\n",
        "- [ã€åˆå­¸ç­†è¨˜ã€‘å–å¾—Hugging Face API Tokens åˆ°åŸ·è¡Œç°¡å–®LLMå•ç­”å…§å®¹ç”Ÿæˆ(Inference)](https://medium.com/@Ting_YTK/%E5%88%9D%E5%AD%B8%E7%AD%86%E8%A8%98-%E5%8F%96%E5%BE%97hugging-face-api-tokens-%E5%88%B0%E5%9F%B7%E8%A1%8C%E7%B0%A1%E5%96%AEllm%E5%95%8F%E7%AD%94%E5%85%A7%E5%AE%B9%E7%94%9F%E6%88%90-inference-3473baa347f6)\n",
        "- [LLM Note Day 23 - LangChain ä¸­äºŒæŠ€èƒ½ç¿»è­¯](https://ithelp.ithome.com.tw/articles/10335721)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5x_sO1-eV2l"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Part 2: Customize 3 Math Tools [30åˆ†]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtjruBg_iauZ"
      },
      "source": [
        "ğŸ”ºè«‹ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºï¼Œå‰µå»º 3 å€‹ LangChain å·¥å…· for åŸºæœ¬æ•¸å­¸é‹ç®—ï¼š\n",
        "\n",
        "1. **Install and import necessary libraries**\n",
        "2. **Define Tools**\n",
        "\n",
        "    - è«‹å°‡ä¸‰å€‹å·¥å…·åˆ†åˆ¥å‘½åæˆï¼š `divide`, `minus`, `exponentiate`\n",
        "    - ä½¿ç”¨ `langchain_core.tools` æ¨¡çµ„ä¸­çš„ @tool decorator ä¾†å®šç¾©æ¯å€‹å·¥å…·ï¼Œéœ€å®šç¾©æ¯å€‹å·¥å…·çš„åƒæ•¸å’Œå›å‚³é¡å‹ <18åˆ†>\n",
        "    - åœ¨å·¥å…·çš„å‡½æ•¸ä¸­ç·¨å¯«ç¨‹å¼ç¢¼ï¼Œä»¥åŸ·è¡Œç‰¹å®šçš„æ•¸å­¸é‹ç®— <6åˆ†>\n",
        "\n",
        "        ğŸŒŸHINTSğŸŒŸ\n",
        "      - divide: ç¬¬1å€‹æ•´æ•¸ é™¤ä»¥ ç¬¬2å€‹æ•´æ•¸\n",
        "      - minus: ç¬¬1å€‹æ•´æ•¸ æ¸› ç¬¬2å€‹æ•´æ•¸\n",
        "      - exponentiate: ç¬¬1å€‹æ•´æ•¸çš„(ç¬¬2å€‹æ•´æ•¸)æ¬¡æ–¹\n",
        "\n",
        "3. **Store the Tools** <6åˆ†>\n",
        "  - è«‹å°‡ä¸‰å€‹å·¥å…·ä»¥ list æ–¹å¼ï¼Œå„²å­˜åœ¨ `tools` é€™å€‹è®Šæ•¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1kGh5ar0gIxN"
      },
      "outputs": [],
      "source": [
        "## 1. Install and import necessary libraries\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dqd5_lFfgZT9"
      },
      "outputs": [],
      "source": [
        "## 2. Define Tools\n",
        "@tool\n",
        "def divide(a: int, b:int) -> float:\n",
        "  \"\"\"Divide the first integer by the second integer.\"\"\"\n",
        "  return a/b\n",
        "\n",
        "@tool\n",
        "def minus(a: int, b:int) -> int:\n",
        "  \"\"\"Subtract the second integer from the first integer.\"\"\"\n",
        "  return a-b\n",
        "\n",
        "@tool\n",
        "def exponentiate(a: int, b:int) -> float:\n",
        "  \"\"\"The first integer raised to the power of the second integer.\"\"\"\n",
        "  return a**b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t0a-VTFoJapR"
      },
      "outputs": [],
      "source": [
        "## 3. Store the Tools\n",
        "tools = [divide, minus, exponentiate]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFLhceWRVAoE"
      },
      "source": [
        "### åƒè€ƒè³‡æ–™\n",
        "\n",
        "- [æœ€å…¨é¢åˆæœ€æµ…æ˜¾æ˜“æ‡‚çš„Langchainå¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ï¼ˆä¸‹ï¼‰](https://juejin.cn/post/7345869813329936399)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzyF5dqzeYeV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Part 3: Combine Tools with Agent [45åˆ†]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmOrxYjSmTx4"
      },
      "source": [
        "ğŸ”ºè«‹ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºï¼Œçµåˆ Part 2 çš„ `tools` å‰µå»º 1 å€‹ agent\n",
        "0. **è«‹ä¿ç•™ Part 2 å„²å­˜çš„ `tools`**\n",
        "  - <mark>å¦‚æœ part 2 part 3 åˆ†æˆå…©æ¬¡åšï¼Œè«‹å…ˆè·‘ä¸€æ¬¡ part 2 çš„ codeï¼Œå†ç¹¼çºŒåŸ·è¡Œä»¥ä¸‹æ“ä½œ\n",
        "1. **Install and import necessary libraries**\n",
        "2. **Define an LLM** <5åˆ†>\n",
        "  - é¸ç”¨ä¸€å€‹ HuggingFace æ¨¡å‹\n",
        "\n",
        "\n",
        "3. **Define Prompt** <20åˆ†>\n",
        "  - ä½¿ç”¨ `ChatPromptTemplate.from_messages()` å‰µé€ ä¸€å€‹ prompt <\n",
        "  - é€™æ ¼ç¨‹å¼ç¢¼æœƒé•·å¾—åƒï¼š\n",
        "    ```python\n",
        "      prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "          (\"Â¿Â¿\", \"â“â“â“\",),\n",
        "          (\"placeholder\", \"â“â“â“\"),\n",
        "          (\"Â¿Â¿\", \"â“â“â“\"),\n",
        "          (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "        ]\n",
        "      )\n",
        "    ```\n",
        "  - ç•¶ç„¶ä½ ä¹Ÿå¯ä»¥è‡ªç”±ç™¼æ®ğŸ³\n",
        "  \n",
        "4. **Define Agent Chain** <15åˆ†>\n",
        "  - ä½¿ç”¨ `initialize_agent()` å®šç¾©ä¸€å€‹ agent chain\n",
        "  - <mark>å¯èƒ½éœ€è¦çš„æ¨¡çµ„å’Œå‡½æ•¸\n",
        "    ```python\n",
        "      from langchain.agents import AgentType\n",
        "      from langchain.agents import initialize_agent\n",
        "    ```\n",
        "5. **Invoke Agent Executor** <5åˆ†>\n",
        "  - ä½¿ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼å°å‡ºæ¨¡å‹çš„å›è¦†çµæœ\n",
        "    ```python\n",
        "      ## invoke agent_executor åˆ—å°æ¨¡å‹çš„å›è¦†çµæœ\n",
        "      result = agent_executor.invoke({\n",
        "      \"input\": \"Take 2 to the power of 6, then divide this result obtained by the result of 24 minus 8, then square the whole result\"\n",
        "      })\n",
        "\n",
        "      print(result)\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "neyNksnvI7vg"
      },
      "outputs": [],
      "source": [
        "# 1. Install and import necessary libraries\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKiZ1xioPs6V",
        "outputId": "851ee534-48fd-441c-ade1-0b60595f304b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# 2. å®šç¾© LLM\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm = HuggingFaceEndpoint(repo_id=repo_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5j1_KEEKgg05"
      },
      "outputs": [],
      "source": [
        "# 3. å®šç¾© prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "   [\n",
        "     (\"user\", \"I have a question. {input}. Please carefully find the correct algorithm.\"),\n",
        "     (\"assistant\", \"Okay, let me tell you the answer.\")\n",
        "   ]\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhiEgFg0962b",
        "outputId": "46bd653f-1315-4102-c5f9-a3ce4e7b7771"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# 4. å®šç¾© agent_chain\n",
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose=True\n",
        ")\n",
        "agent_executor = prompt | agent_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiyUOSHxGFLc",
        "outputId": "30400609-04a9-450d-f149-6906ceb2ff5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"divide\",\n",
            "  \"action_input\": {\n",
            "    \"a\": 64,\n",
            "    \"b\": 16\n",
            "  }\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m4.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to subtract 8 from 24 first.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"minus\",\n",
            "  \"action_input\": {\n",
            "    \"a\": 24,\n",
            "    \"b\": 8\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m16\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I can find 2 raised to the power of 6 and divide it by 16.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"exponentiate\",\n",
            "  \"action_input\": {\n",
            "    \"a\": 2,\n",
            "    \"b\": 6\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m64\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I can divide 64 by 16.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"divide\",\n",
            "  \"action_input\": {\n",
            "    \"a\": 64,\n",
            "    \"b\": 16\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m4.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I need to square 4.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"exponentiate\",\n",
            "  \"action_input\": {\n",
            "    \"a\": 4,\n",
            "    \"b\": 2\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m16\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I know what to respond.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The final answer to your question is 16.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': ChatPromptValue(messages=[HumanMessage(content='I have a question. Take 2 to the power of 6, then divide this result obtained by the result of 24 minus 8, then square the whole result. Please carefully find the correct algorithm.'), AIMessage(content='Okay, let me tell you the answer.')]), 'output': 'The final answer to your question is 16.'}\n"
          ]
        }
      ],
      "source": [
        "# 5. åˆ—å°æ¨¡å‹çš„å›è¦†çµæœ\n",
        "result = agent_executor.invoke({\n",
        "    \"input\": \"Take 2 to the power of 6, then divide this result obtained by the result of 24 minus 8, then square the whole result\"\n",
        " })\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFbXR8C3auc9"
      },
      "source": [
        "### åƒè€ƒè³‡æ–™\n",
        "\n",
        "- [[LangChain for LLM Application Development] èª²ç¨‹ç­†è¨˜- Agents](https://hackmd.io/@YungHuiHsu/rkBMDgRM6?utm_source=preview-mode&utm_medium=rec)\n",
        "- [LangChain 9 æ¨¡å‹Model I/O èŠå¤©æç¤ºè¯ChatPromptTemplate, å°‘é‡æ ·æœ¬æç¤ºè¯FewShotPrompt](https://blog.csdn.net/zgpeace/article/details/134608897)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbls4nZXMCpM"
      },
      "source": [
        "## ğŸŒŸBONUS: é‡å° YT å½±ç‰‡å•å•é¡Œ [20åˆ†]ğŸŒŸ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0S8S35DMFCE"
      },
      "source": [
        "1. ä½¿ç”¨ [YouTube transcripts Loaders](https://python.langchain.com/v0.1/docs/integrations/document_loaders/youtube_transcript/) æŠ“å–ä»»ä½•ã€Œé•·åº¦å¤§æ–¼10åˆ†é˜ã€çš„ YouTubeå½±ç‰‡çš„ccå­—å¹•ï¼Œæœƒè®€æˆä¸€å€‹é•·æ–‡æœ¬\n",
        "2. å°‡æ­¤æ–‡æœ¬åšæˆå‘é‡ï¼Œå­˜åˆ°ä¸€å€‹ VectorStore DB ï¼ˆå»ºè­°ä½¿ç”¨ [Chroma](https://python.langchain.com/v0.1/docs/integrations/vectorstores/chroma/)ï¼‰\n",
        "3. å»ºç«‹ä¸€å€‹ retriever ä»¥åŠåŸºæ–¼æ­¤ retriever çš„ LLM chainï¼ˆ[åŠ©æ•™èª²çš„Colab](https://colab.research.google.com/drive/1T7Q4X9qeppvMuYI3pJLN4OfD9L_F6YMx?usp=sharing)æœ‰æ•™ã„›ğŸ³ï¼‰\n",
        "4. è¨­è¨ˆä¸€å€‹å’Œæ­¤å½±ç‰‡æœ‰é—œçš„å•é¡Œ\n",
        "5. æœ€å¾Œè«‹æŠŠ  **`chain.invoke('è²¼ä¸Šä½ è‡ªå·±è¨­è¨ˆçš„å•é¡Œ')`  çš„çµæœåˆ—å°å‡ºä¾†**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Db2vwsb38TcT"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  youtube-transcript-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DuEhEXP3S9sn"
      },
      "outputs": [],
      "source": [
        "# Install and import necessary libraries\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnjuDTBa71Vn",
        "outputId": "5ce94933-ecd0-41d1-9321-f32cc0e92535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æˆ‘å€‘æœ‰ 4 splitted documents\n",
            "å¹³å‡æ¯å€‹ splitted document æœ‰ 2,586 characters\n"
          ]
        }
      ],
      "source": [
        "# YouTube transcripts Loaders\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=lYtdZo0aW50\", add_video_info=False\n",
        ")\n",
        "film = loader.load()\n",
        "\n",
        "# Split the text\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
        "sp_film = text_splitter.split_documents(film)\n",
        "\n",
        "num_total_characters = sum([len(x.page_content) for x in sp_film])\n",
        "\n",
        "print(f\"æˆ‘å€‘æœ‰ {len(sp_film)} splitted documents\")\n",
        "print(f\"å¹³å‡æ¯å€‹ splitted document æœ‰ {num_total_characters / len(sp_film):,.0f} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFc8F6DJ9UI1",
        "outputId": "07918896-618a-4245-a9d3-656b6350ddc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['459a7d18-5de8-417b-804d-786cba33fcc0',\n",
              " 'b8763bde-3966-46d4-b0f4-40614cbaf8de',\n",
              " '70188cc7-b140-4e18-b7c6-fad7e3075d54',\n",
              " 'a171c430-cc42-425a-a37d-4e7e5a1cc8f3']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the embeddings engine ready\n",
        "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-l6-v2\",\n",
        "    api_key=api_token,\n",
        ")\n",
        "\n",
        "# Set the vectorstore\n",
        "vectorstoreDB = Chroma(embedding_function = embeddings,\n",
        "                        persist_directory = './Chroma_DATABASE')\n",
        "vectorstoreDB.add_documents(sp_film)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S3ZVy0xT98Es"
      },
      "outputs": [],
      "source": [
        "# Define retriever\n",
        "retriever = vectorstoreDB.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "## Define the prompt\n",
        "template = \"\"\"Please answer the following question based on the context provided:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Set the LLM chain\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WVGiuWNl_G8Z"
      },
      "outputs": [],
      "source": [
        "# Question\n",
        "user_query = \"How did the speaker rebel when he was 14?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fia2fOiy_LkR",
        "outputId": "3d294cd8-e81b-4bb4-ef7f-d9ce4b9daaab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAnswer: The speaker rebelled by doing his math homework in secret, locking himself in a room, and hiding it from his father. When his father discovered him, the speaker lied and claimed he was masturbating instead, hoping his father would not be disappointed in him for doing homework. The speaker also mentioned that his parents are very traditional and hard to please, making it difficult for him to bond with them or enjoy simple pleasures like watching TV.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Invoke the chain\n",
        "chain.invoke(user_query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
